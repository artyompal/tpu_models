
Create an instance:

gcloud config set project tpu-test-246716
ctpu up --tpu-size=v3-8 --machine-type n1-standard-4 --zone us-central1-a --name tpu3-1
ctpu up --tpu-size=v2-8 --machine-type n1-highmem-2  --zone us-central1-b --name tpu2-1
ctpu up --tpu-size=v2-8 --machine-type n1-highmem-2 --zone us-central1-b --name pre-2 --preemptible --disk-size-gb=120 --vm-only --noconf

gcloud compute firewall-rules create tensorboard --allow tcp:6006 --source-tags=tpu3-1,tpu3-2 --source-ranges=0.0.0.0/0


Configure an instance:

sudo apt install -y mc htop python-tk

echo export PYTHONPATH=$HOME/tpu_models/models >>~/.bashrc
export PYTHONPATH=$HOME/tpu_models/models

git config --global core.editor "vim"
git config --global diff.tool "vimdiff"
git config --global --add difftool.prompt false
git config --global user.name "artyom"
git config --global user.email "artyom@artyom"
git config --global alias.alias "config --get-regexp ^alias\."
git config --global alias.lg "log --graph --pretty=format:'%Cgreen(%h) -%Cblue(%ci) %C(yellow)<%an>%d%Creset %s' --abbrev-commit"

pip install --user Cython matplotlib opencv-python-headless pyyaml Pillow
pip install --user 'git+https://github.com/cocodataset/cocoapi#egg=pycocotools&subdirectory=PythonAPI'

git clone git@github.com:artyompal/tpu_models.git
cd tpu_models/scripts/


Train a model:

gcloud beta compute --project "tpuproj-245020" ssh --zone "us-central1-b" "new2-1"
gcloud beta compute --project "tpuproj-245020" ssh --zone "us-central1-a" "new3-1"
gcloud beta compute --project "tpuproj-245020" ssh --zone "us-central1-b" "pre-1"

cd tpu_models/scripts/
git pull
./train_on_dataset.sh human_parts 2.4.0
./train_on_dataset.sh part_4 2.0.4

./train_on_fold.sh part_0 2.0.4 0
./train_on_fold.sh human_parts 2.0.6 0


Debug model:

def restore_from_checkpoint(self):
  print([n.name for n in tf.get_default_graph().as_graph_def().node])

# import the inspect_checkpoint library
from tensorflow.python.tools import inspect_checkpoint as chkp

# print all tensors in checkpoint file
chkp.print_tensors_in_checkpoint_file('/tmp/model.ckpt', tensor_name='', all_tensors=True)


Monitor training:

cat training.log | grep -oE '(.AP50.:[ .0-9]+|Restoring.*)' | uniq
cat `ls -ct1 | head -n 1` | grep -oE '(.AP50.:[ .0-9]+|Restoring.*)' | uniq

ls -ct1 | head -n 1; cat `ls -ct1 | head -n 1` | grep -oE '(.AP50.:[ .0-9]+|Restoring.*)' | uniq
ls -ct1 | head -n 1; cat `ls -ct1 | head -n 1` | grep -oE '(.AP50.:[ .0-9]+)' | uniq | sort -r | head -n 1


Export a model:

./export_saved_model.sh human_parts 1.0.3 5000
./export_saved_model.sh part_0 1.1.0 25000


Infer predictions:

CUDA_VISIBLE_DEVICES=1 ./docker_run.sh python inference.py predictions/1.0.3_human_parts.pkl best_models/sep_11/1.0.3-human_parts
CUDA_VISIBLE_DEVICES=0 ./docker_run.sh python inference.py predictions/1.1.0_part_0.pkl best_models/sep_11/1.1.0-part_0

for model_dir in ../best_models/sep_22/*fold_0*
do ./docker_run.sh python inference.py $model_dir
done


Training ImageNet:

export DEPTH=101
python resnet_main.py --tpu=$HOSTNAME --data_dir=gs://new_tpu_storage/imagenet/ \
    --model_dir=gs://new_tpu_storage/resnet$DEPTH/ --resnet_depth=$DEPTH \
    --config_file=configs/resnet$DEPTH.yaml 2>&1 | tee -a ~/resnet$DEPTH.log

cat resnet152.log | grep 'Saving dict' | grep -v INFO
